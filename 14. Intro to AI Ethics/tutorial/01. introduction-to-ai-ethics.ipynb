{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ce5960",
   "metadata": {
    "papermill": {
     "duration": 0.003538,
     "end_time": "2021-11-09T00:05:52.372302",
     "exception": false,
     "start_time": "2021-11-09T00:05:52.368764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Welcome to the AI Ethics course!\n",
    "\n",
    "AI increasingly has an impact on everything from social media to healthcare.  AI is used to make credit card decisions, to conduct video surveillance in airports, and to inform military operations.  These technologies have the potential to harm or help the people that they serve.  By applying an ethical lens, we can work toward identifying the harms that these technologies can cause to people and we can design and build them to reduce these harms - or decide not to build them.\n",
    "\n",
    "**This course has no prerequisites**, and we don’t assume any programming background.  \n",
    "\n",
    "Your instructors **[Var Shankar](https://www.kaggle.com/var0101)** (who has worked on AI ethics in industry) and **[Alexis Cook](https://www.kaggle.com/alexisbcook)** (who has designed and trained AI models) have collaborated to build this applied and practical course.  In the exercises, you will run code to train and investigate AI models.  If you are already on a team developing AI products and don’t know where to start, we provide actionable suggestions.   \n",
    "\n",
    "This course covers several topics: \n",
    "- In the **human-centered design** lesson, you’ll learn how to design an AI system to ensure that it serves the needs of the people that it is intended for.\n",
    "- In the **bias** lesson, you’ll determine how AI systems can learn to discriminate against certain groups.\n",
    "- In the **fairness** lesson, you’ll learn to quantify the extent of the bias in AI systems.  \n",
    "- In the **model cards** lesson, you’ll learn how to use a popular framework for improving public accountability for AI models.\n",
    "\n",
    "As the field of AI evolves, so does AI ethics.  As a wise friend once told us, _“Ethics is a conversation.”_  This course can help you start that conversation, but not finish it.  Some topics that we do not cover include: AI’s potential impact on the digital technology divide between the rich and the poor, on jobs, and on the capabilities of authoritarian governments, among others.  That said, throughout the course, we recommend next steps for continuing your learning and following the ethical conversation as it continues to evolve. \n",
    "\n",
    "# Get started!\n",
    "\n",
    "Ready to start the course? **[Learn about human-centered design](https://www.kaggle.com/var0101/human-centered-design-for-ai)** in the next tutorial!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653eaa1",
   "metadata": {
    "papermill": {
     "duration": 0.002297,
     "end_time": "2021-11-09T00:05:52.377738",
     "exception": false,
     "start_time": "2021-11-09T00:05:52.375441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/ai-ethics/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.102281,
   "end_time": "2021-11-09T00:05:52.992639",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-09T00:05:41.890358",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
